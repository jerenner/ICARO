{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitor NB - Penthesilea - Th\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on  Wed Sep 27 19:38:46 2017\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import functools\n",
    "import time\n",
    "print(\"Running on \", time.asctime())\n",
    "\n",
    "import numpy             as np\n",
    "import scipy.stats       as stats\n",
    "import tables            as tb\n",
    "import pandas            as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import invisible_cities.core.core_functions as coref\n",
    "import invisible_cities.core.fit_functions  as fitf\n",
    "import invisible_cities.reco.dst_functions  as dstf\n",
    "import invisible_cities.io  .dst_io         as dstio\n",
    "import invisible_cities.reco.corrections    as corrf\n",
    "\n",
    "import invisible_cities.icaro.hst_functions as hst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "np.warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"]          = 8, 6\n",
    "plt.rcParams[\"font.size\"]               = 15\n",
    "plt.rcParams[\"figure.max_open_warning\"] = 100\n",
    "\n",
    "profOpt = \"--k\"\n",
    "fitOpt  = \"r\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fselection(sels):\n",
    "    \"\"\" makes the all of different selections\n",
    "    \"\"\"\n",
    "    return functools.reduce(lambda x, y: np.logical_and(x, y), sels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_folder  = '/Users/hernando/investigacion/NEXT/data/run2'\n",
    "tags = '/prod/may17/alex'\n",
    "\n",
    "def load_dst(run_number, tags='/prod/may17/alex'):\n",
    "    \"\"\" load dst and return full data, train and test selections\n",
    "    \"\"\"\n",
    "    inputfilename = input_folder + \"/{0}{1}/dst/dst_{0}.root.h5\".format(run_number, tags)\n",
    "    print('load dst ', inputfilename)\n",
    "    data = dstf.load_dst(inputfilename, \"DST\", \"Events\")\n",
    "    return data\n",
    "    #data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogramming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xbins  = 100\n",
    "xybins = (40, 40)\n",
    "range_none = (0., 0.)\n",
    "\n",
    "def mh1(data, varname, bins=xbins, range=range_none, fig=None, ax=None):\n",
    "    if (not ax):\n",
    "        fig, ax = plt.subplots()\n",
    "    dat = getattr(data, varname)\n",
    "    ns = len(dat)\n",
    "    if (range[0] >= range[1]):\n",
    "        range = np.min(dat), np.max(dat)\n",
    "    cc = ax.hist(dat, bins, range=range)\n",
    "    counts, edges = cc[0], cc[1]\n",
    "    xpos = edges[0]+0.6*(edges[-1]-edges[0])\n",
    "#    ypos = np.min(counts)+0.7*(np.max(counts)-np.min(counts))\n",
    "    ypos = 0.7*np.max(counts)\n",
    "    sel = np.logical_and(dat > range[0], dat < range[1])\n",
    "    ss = stats.describe(dat[sel])\n",
    "    nos, mean, rms = int(ss.nobs), float(ss.mean), float(np.sqrt(ss.variance))  \n",
    "    epsilon = (1.*nos)/(1.*ns)\n",
    "    ss  = ' $\\epsilon$ = {0:.3f} \\n $n$ = {1:}'.format(epsilon, nos)\n",
    "    ss += ' \\n $\\mu$ = {0:.3f} \\n $\\sigma$ = {1:.3f}'.format(mean, rms)\n",
    "    ax.text(xpos, ypos, ss, fontsize=11)\n",
    "    # ax.text(xpos, ypos, dat[sel].describe(), fontsize=11)\n",
    "    # fig.text(1., 0.2, dat[sel].describe())\n",
    "    ax.set_xlabel(varname)\n",
    "    return\n",
    "\n",
    "def mh2(data, xvar, yvar, bins=xybins, range=(range_none, range_none), \n",
    "        fig=None, ax=None):\n",
    "    # get data, ranges, axis\n",
    "    if (ax == None):\n",
    "        fig, ax = plt.subplots()\n",
    "    xs, ys = getattr(data, xvar), getattr(data, yvar)\n",
    "    xrange, yrange = range\n",
    "    if (xrange[0] >= xrange[1]):\n",
    "        xrange = np.min(xs), np.max(xs)\n",
    "    if (yrange[0] >= yrange[1]):\n",
    "        yrange = np.min(ys), np.max(ys)\n",
    "    # 2d histogram\n",
    "    cc = ax.hist2d(xs, ys, bins=bins, range=(xrange, yrange), cmap='jet')\n",
    "    ax.set_xlabel(xvar)\n",
    "    ax.set_ylabel(yvar)\n",
    "    fig.colorbar(cc[-1], ax=ax)\n",
    "    sel = fselection([xs > xrange[0], xs < xrange[1],\n",
    "                      ys > yrange[0], ys < yrange[1]])\n",
    "    # profile\n",
    "    px, py, pk = fitf.profileX(xs[sel], ys[sel], bins[0], \n",
    "                               xrange=xrange, yrange=yrange)\n",
    "    ax.plot(px, py, profOpt)\n",
    "    # stats\n",
    "    ss1 = stats.describe(xs[sel])\n",
    "    ss2 = stats.describe(ys[sel])\n",
    "    nobs, mu1, sig1 = ss1.nobs, ss1.mean, np.sqrt(ss1.variance)\n",
    "    nobs, mu2, sig2 = ss2.nobs, ss2.mean, np.sqrt(ss2.variance)\n",
    "    corr = np.corrcoef(xs[sel], ys[sel])\n",
    "    # print(corr)\n",
    "    ypos = yrange[0]+0.5*(yrange[1]-yrange[0])\n",
    "    xpos = xrange[0]+0.6*(xrange[1]-xrange[0])\n",
    "    n = len(data)\n",
    "    epsilon = (1.*nobs)/(1.*n)\n",
    "    ss  = \" $\\epsilon$ = {0:.3f} \\n $n$ = {1:}\".format(epsilon, nobs) \n",
    "    ss += \"\\n $\\mu_x$ = {0:.3f} \\n $\\sigma_x$ = {1:.3f}\".format(mu1, sig1)\n",
    "    ss += \"\\n $\\mu_y$ = {0:.3f} \\n $\\sigma_y$ = {1:.3f}\".format(mu2, sig2)\n",
    "    ss += \"\\n \"+r\"$\\rho$ = {0:.3f} \".format(float(corr[0, 1]))\n",
    "    # print(ss)\n",
    "    ax.text(xpos, ypos, ss, fontsize=11, color='white')\n",
    "    return\n",
    "\n",
    "def plt_hist(data, vars):\n",
    "    ns = int(len(vars)/2)\n",
    "    if (2*ns < len(vars)): \n",
    "        ns = ns+1 \n",
    "    fig, axs = plt.subplots(ns, 2, figsize=(5.5*2, 4.5*ns))\n",
    "    axs = axs.ravel()\n",
    "    for i, var in enumerate(vars):\n",
    "        if (len(var) == 3):\n",
    "            mh1(data, var[0], bins=var[-2], range=var[-1], \n",
    "                fig = fig, ax=axs[i])\n",
    "        else:\n",
    "            mh2(data, var[0], var[1], bins=var[-2], range=var[-1], \n",
    "                fig = fig, ax=axs[i])\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_NN_hits(hits_all,hits_nonNN):\n",
    "\n",
    "    # Iterate through the nonNN dictionary and update the energies including the NN hits from the \"all\" dictionary.\n",
    "    for (evt,hc) in hits_nonNN.items():\n",
    "\n",
    "        # Get the corresponding collection of all hits.\n",
    "        hc_all = hits_all[evt]\n",
    "            \n",
    "        # Add energy from all NN hits to hits in closest slice.\n",
    "        for h1 in hc_all.hits:\n",
    "\n",
    "            if(h1.Q == NN):\n",
    "\n",
    "                # Find the hits to which the energy will be added.\n",
    "                zdist_min = -1\n",
    "                h_add = []\n",
    "                for h2 in hc.hits:\n",
    "                    zdist = np.abs(h1.Z - h2.Z)\n",
    "                    if(zdist_min < 0 or zdist < zdist_min):\n",
    "                        zdist_min = zdist\n",
    "                        h_add = []\n",
    "                        h_add.append(h2)\n",
    "                    elif(zdist == zdist_min):\n",
    "                        h_add.append(h2)\n",
    "\n",
    "                # Add the energy.\n",
    "                hadd_etot = sum([ha.E for ha in h_add])\n",
    "                for ha in h_add:\n",
    "                    ha.energy += h1.E*(ha.E/hadd_etot)\n",
    "                    \n",
    "        # Check the sum of the energy.\n",
    "        #e1 = sum([hh.E for hh in hc_all.hits])\n",
    "        #e2 = sum([hh.E for hh in hc.hits])\n",
    "        #if(abs(e1 - e2) > 0.001):\n",
    "        #    print(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run numbers and lifetime values for correction\n",
    "l_rnum   = [4717]\n",
    "l_tlife  = [1598]\n",
    "l_nfiles = [596]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l_hitc = []\n",
    "for rnum in l_rnum:\n",
    "    \n",
    "    fname = \"/Users/jrenner/IFIC/IC-1/invisible_cities/database/NEW/{0}/tracks/tracks_{1}.h5\".format(rnum,rnum)\n",
    "    hits_all = load_hits(fname)\n",
    "    hits = load_hits_skipping_NN(fname)\n",
    "\n",
    "    # Modifies the list of non-NN hits.\n",
    "    merge_NN_hits(hits_all,hits)\n",
    "    \n",
    "    # Save the hit collection that no longer contains NN hits.\n",
    "    l_hitc.append(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the corrected hit collections (summed over all runs) for \n",
    "#  fully corrected (c), geometry-only corrected (g), tau-only corrected (t), and uncorrected (u) events.\n",
    "hitc_uevt = []; hitc_cevt = []; hitc_gevt = []; hitc_tevt = []\n",
    "for hitc, tlife in zip(l_hitc,l_tlife):\n",
    "\n",
    "    for ee,hc in hitc.items():\n",
    "        hc_ucorr = []; hc_corr = []; hc_gcorr = []; hc_tcorr = []\n",
    "        for hh in hc.hits:\n",
    "            \n",
    "            hecorr = hh.E*fcorr(hh.X,hh.Y)/np.exp(-hh.Z/tlife)\n",
    "            hegcorr = hh.E*fcorr(hh.X,hh.Y)\n",
    "            hetcorr = hh.E/np.exp(-hh.Z/tlife)\n",
    "            \n",
    "            hucorr = Hit(0,Cluster(0, xy(hh.X,hh.Y), xy(0,0), 0),hh.Z,hh.E)\n",
    "            hcorr  = Hit(0,Cluster(0, xy(hh.X,hh.Y), xy(0,0), 0),hh.Z,hecorr)\n",
    "            hgcorr = Hit(0,Cluster(0, xy(hh.X,hh.Y), xy(0,0), 0),hh.Z,hegcorr)\n",
    "            htcorr = Hit(0,Cluster(0, xy(hh.X,hh.Y), xy(0,0), 0),hh.Z,hetcorr)\n",
    "            \n",
    "            hc_ucorr.append(hucorr); hc_corr.append(hcorr); hc_gcorr.append(hgcorr); hc_tcorr.append(htcorr)\n",
    "        \n",
    "        # Only save events with >= 2 hits.\n",
    "        if(len(hc_corr) >= 2):\n",
    "            hitc_uevt.append(hc_ucorr)\n",
    "            hitc_cevt.append(hc_corr)\n",
    "            hitc_gevt.append(hc_gcorr)\n",
    "            hitc_tevt.append(hc_tcorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A_Ec = []; A_Ec_avg = []; A_Ec_tau = []; A_Ec_geo = []; A_E0 = []\n",
    "A_xavg = []; A_yavg = []; A_zavg = []; A_ravg = []\n",
    "\n",
    "for ee in range(len(hitc_cevt)):\n",
    "    \n",
    "    # Compute the corrected energy and average coordinates.\n",
    "    evt_E = sum([hh.E for hh in hitc_cevt[ee]])\n",
    "    evt_X = sum([hh.X*hh.E for hh in hitc_cevt[ee]])\n",
    "    evt_Y = sum([hh.Y*hh.E for hh in hitc_cevt[ee]])\n",
    "    evt_Z = sum([hh.Z*hh.E for hh in hitc_cevt[ee]])\n",
    "    if(evt_E > 0):\n",
    "        evt_X /= evt_E\n",
    "        evt_Y /= evt_E\n",
    "        evt_Z /= evt_E\n",
    "    evt_R = np.sqrt(evt_X**2 + evt_Y**2)\n",
    "    \n",
    "    # Compute the energy with other corrections.\n",
    "    evt_E_uncorr = sum([hh.E for hh in hitc_uevt[ee]])\n",
    "    evt_E_cgeo = sum([hh.E for hh in hitc_gevt[ee]])\n",
    "    evt_E_ctau = sum([hh.E for hh in hitc_tevt[ee]])\n",
    "    \n",
    "    # Add to distributions.\n",
    "    A_Ec.append(evt_E)\n",
    "    A_Ec_avg.append(evt_E_uncorr*fcorr(evt_X,evt_Y)/np.exp(-evt_Z/tlife))\n",
    "    A_Ec_tau.append(evt_E_ctau)\n",
    "    A_Ec_geo.append(evt_E_cgeo)\n",
    "    A_E0.append(evt_E_uncorr)\n",
    "    A_xavg.append(evt_X)\n",
    "    A_yavg.append(evt_Y)\n",
    "    A_zavg.append(evt_Z)\n",
    "    A_ravg.append(evt_R)\n",
    "\n",
    "# Convert to numpy arrays.\n",
    "A_Ec = np.array(A_Ec)\n",
    "A_Ec_avg = np.array(A_Ec_avg)\n",
    "A_Ec_tau = np.array(A_Ec_tau)\n",
    "A_Ec_geo = np.array(A_Ec_geo)\n",
    "A_E0 = np.array(A_E0)\n",
    "A_xavg = np.array(A_xavg)\n",
    "A_yavg = np.array(A_yavg)\n",
    "A_zavg = np.array(A_zavg)\n",
    "A_ravg = np.array(A_ravg)\n",
    "\n",
    "print(\"Events after Paolina analysis: {0}\".format(len(A_eblob1)))\n",
    "print(\"Events in key quantities: {0}\".format(len(A_Ec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
